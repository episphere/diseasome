import localforage from 'https://cdn.skypack.dev/localforage';

import pako from 'https://cdnjs.cloudflare.com/ajax/libs/pako/2.1.0/pako.esm.mjs'
let pgsTxts = localforage.createInstance({
    name: "pgsTxts",
    storeName: "pgsTxts",
})
let sdk = {}
// 23andMe ///////////////////////////////////////////////////////////////////////////////////
// get all users urls genotype data (23andMe, illumina, ancestry etc)-------------------------------
sdk.getUsers = async function (length) {
    let arr = []
    let url = 'https://corsproxy.io/?https://opensnp.org/users.json'
    let dt = (await (await fetch(url)).json()).sort((a, b) => a.id - b.id).filter(row => row.genotypes.length > 0).map(x => {

        // keep user urls  with one or more 23andme files
        dt.genotypes.map(i => {
            if (x.genotypes.length > 0 && i.filetype == "23andme") {
                let innerObj = {};
                innerObj["name"] = dt["name"];
                innerObj["id"] = dt["id"];
                innerObj["genotype.id"] = i.id;
                innerObj["genotype.filetype"] = i.filetype;
                innerObj["genotype.download_url"] = i.download_url.replace("http", "https")
                arr.push(innerObj)

            }
        })
        return arr
    })
   // get texts and run qc
    let urls23 = arr.map(x => x["genotype.download_url"]).slice(0, length)
    let txts23 = []
    console.log("total users = ", urls23.length)
    for (let i = 0; i < urls23.length; i++) {
        console.log("user: ", urls23[i])
        let url2 = 'https://corsproxy.io/?' + urls23[i]
        let user = (await (await fetch(url2)).text())
        if (user.substring(0, 37) == '# This data file generated by 23andMe') {
            console.log("This is a valid 23andMe file") //, user.substring(0, 37))
            let parsedUser = await parse23(user, urls23[i])
            txts23.push(parsedUser)
        } else {
            console.log("ERROR:This is NOT a valid 23andMe file:", user.substring(0, 37))
        }
    }
    return txts23
}

   // get texts and run qc
sdk.get23 = async function( urls){

   let urls23 = arr.map(x => x["genotype.download_url"]).slice(0, length)
   let txts23 = []
   console.log("total users = ", urls23.length)
   for (let i = 0; i < urls23.length; i++) {
       console.log("user: ", urls23[i])
       let url2 = 'https://corsproxy.io/?' + urls23[i]
       let user = (await (await fetch(url2)).text())
       if (user.substring(0, 37) == '# This data file generated by 23andMe') {
           console.log("This is a valid 23andMe file") //, user.substring(0, 37))
           let parsedUser = await parse23(user, urls23[i])
           txts23.push(parsedUser)
       } else {
           console.log("ERROR:This is NOT a valid 23andMe file:", user.substring(0, 37))
       }
   }
   return txts23
}
// create 23andme obj and data --------------------------
sdk.parse23 = async function(txt, url) {
    // normally info is the file namesdk.
    let obj = {}
    let rows = txt.split(/[\r\n]+/g)
    obj.txt = txt
    obj.url = url

    let n = rows.filter(r => (r[0] == '#')).length
    obj.meta = rows.slice(0, n - 1).join('\r\n')
    obj.cols = rows[n - 1].slice(2).split(/\t/)
    obj.dt = rows.slice(n)
    obj.dt = obj.dt.map((r, i) => {
        r = r.split('\t')
        r[2] = parseInt(r[2])
        // position in the chr
        r[4] = i
        return r
    })
    return obj
}
// PGS ///////////////////////////////////////////////////////////////////////////////
sdk.getscoreFiles = async function (pgsIds) {
    var scores = []
    let i = 0
    while (i < pgsIds.length) {
        console.log("pgsIds[i]",pgsIds.length,pgsIds[i])
        let url = `https://www.pgscatalog.org/rest/score/${pgsIds[i]}`
        await timeout(150); // pgs has 100 queries per minute limit
        let data =
            await (fetch(url)).then(function (response) {
                return response.json()
            })
            .then(function (response) {
                return response
            }).catch(function (ex) {
                console.log("There has been an error: ", ex)
            })
        scores.push(data)    
        i += 1
    }
    return scores
}

sdk.timeout = (ms) => {
    return new Promise(resolve => setTimeout(resolve, ms));
}
//console.log("pgs",await getscoreFiles(["PGS002130"]))

sdk.loadScoreHm = async function(entry, build = 37, range) {
    let txt = ""
    let dt
    dt = await pgsTxts.getItem(entry); // check for users in localstorage
    if (entry == null){
         txt = "no pgs entry provided"
        return txt
    } else {
    txt = ""
    entry = "PGS000000".slice(0, -entry.length) + entry
    // https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS000004/ScoringFiles/Harmonized/PGS000004_hmPOS_GRCh37.txt.gz
    const url = `https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/${entry}/ScoringFiles/Harmonized/${entry}_hmPOS_GRCh${build}.txt.gz` //
    if (range) {
        if (typeof (range) == 'number') {
            range = [0, range]
        }
        txt = pako.inflate(await (await fetch(url, {
            headers: {
                'content-type': 'multipart/byteranges',
                'range': `bytes=${range.join('-')}`,
            }
        })).arrayBuffer(), {
            to: 'string'
        })
    } else {
        txt = pako.inflate(await (await fetch(url)).arrayBuffer(), {
            to: 'string'
        })
    }
    // Check if PGS catalog FTP site is down-----------------------
    let response
    response = await fetch(url) // testing url 'https://httpbin.org/status/429'
    if (response?.ok) {
        ////console.log('Use the response here!');
    } else {
        txt = `:( Error loading PGS file. HTTP Response Code: ${response?.status}`
        document.getElementById('pgsTextArea').value = txt
    }
    txt = await sdk.parsePGS(entry, txt)
    pgsTxts.setItem(entry, txt)
}

    return txt
}

// create PGS obj and data --------------------------
sdk.parsePGS = async function(id, txt) {
    let obj = {
        id: id
    }
    obj.txt = txt
    let rows = obj.txt.split(/[\r\n]/g)
    let metaL = rows.filter(r => (r[0] == '#')).length
    obj.meta = {
        txt: rows.slice(0, metaL)
    }
    obj.cols = rows[metaL].split(/\t/g)

    obj.dt = rows.slice(metaL + 1).map(r => r.split(/\t/g))
    if (obj.dt.slice(-1).length == 1) {
        obj.dt.pop(-1)
    }

    // check betas here and added QC
    let betaIdx = obj.cols.indexOf('effect_weight')
    let betas = obj.dt.map( x => x[betaIdx])
    let qc1= betas.some(el => el < -0.00002) // false, if no beta is less than 0
    let qc2 = betas.some(el => el < 10 ) // false, if beta is greater than 10
    obj.qc = "true"//qcText
    // console.log("id",  id)
    // console.log("!qc1",  !qc1)
    // console.log("!qc2",  !qc2)

    if(!qc1 || !qc2){
           obj.qc = "false"//failed both qc1 and qc2
        }
            

    // parse numerical types
    const indInt = [obj.cols.indexOf('chr_position'), obj.cols.indexOf('hm_pos')]
    const indFloat = [obj.cols.indexOf('effect_weight'), obj.cols.indexOf('allelefrequency_effect')]
    const indBol = [obj.cols.indexOf('hm_match_chr'), obj.cols.indexOf('hm_match_pos')]

    // /* this is the efficient way to do it, but for large files it has memory issues
    obj.dt = obj.dt.map(r => {
        // for each data row
        indFloat.forEach(ind => {
            r[ind] = parseFloat(r[ind])
        })
        indInt.forEach(ind => {
            r[ind] = parseInt(r[ind])
        })
        indBol.forEach(ind => {
            r[ind] = (r[11] == 'True') ? true : false
        })
        return r
    })
    // parse metadata
    obj.meta.txt.filter(r => (r[1] != '#')).forEach(aa => {
        aa = aa.slice(1).split('=')
        obj.meta[aa[0]] = aa[1]
    })
    return obj
}

export {sdk}